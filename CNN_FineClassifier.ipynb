{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os,glob,pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, HighPassFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor(audio):\n",
    "    librosa_audio_data, librosa_sample_rate=librosa.load(audio)\n",
    "    mfccs_features= librosa.feature.mfcc(y=librosa_audio_data, sr= librosa_sample_rate,n_mfcc=50)\n",
    "    ar=np.resize(feature,(50,280))\n",
    "    ar = np.expand_dims(ar, axis=-1)\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor2(audio,sr):\n",
    "    mfccs_features= librosa.feature.mfcc(y=audio, sr= sr,n_mfcc=50)\n",
    "    return mfccs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "def load_data():\n",
    "    for file in glob.glob(r\"D:\\BTP\\infant cry\\donateacry_corpus_cleaned_and_updated_data\\*\"):\n",
    "        label = os.path.basename(file)\n",
    "        if label=='hungry':\n",
    "            continue\n",
    "        for audio in glob.glob(file+\"\\*.wav\"):\n",
    "            x.append(audio)\n",
    "            y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 75\n"
     ]
    }
   ],
   "source": [
    "load_data()\n",
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_time_old(data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    shift=min(shift,0.1*data.shape[0])\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'both':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        if direction == 1:\n",
    "            shift = -shift\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_time(data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    shift=min(shift,0.1*data.shape[0])\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch(signal, time_stretch_rate):\n",
    "    return librosa.effects.time_stretch(signal, time_stretch_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_scale(signal, sr, num_semitones):\n",
    "    return librosa.effects.pitch_shift(signal, sr, num_semitones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_gain(signal, min_factor=0.8, max_factor=1.2):\n",
    "    gain_rate = random.uniform(min_factor, max_factor)\n",
    "    augmented_signal = signal * gain_rate\n",
    "    return augmented_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw audio augmentation\n",
    "augment_raw_audio = Compose(\n",
    "    [\n",
    "        AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.2, p=1),\n",
    "        PitchShift(min_semitones=-8, max_semitones=8, p=1),\n",
    "        HighPassFilter(min_cutoff_freq=2000, max_cutoff_freq=4000, p=1)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151263\n"
     ]
    }
   ],
   "source": [
    "for audio,label in zip(x,y):\n",
    "    signal,sr=librosa.load(audio)\n",
    "    print(signal.shape[0])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data=[]\n",
    "aug_label=[]\n",
    "i=0\n",
    "for audio,label in zip(x,y):\n",
    "        signal,sr=librosa.load(audio)\n",
    "        augmented_signal1=shift_time(signal,sr,0.5,'left')\n",
    "        aug_data.append((augmented_signal1,sr))\n",
    "        aug_label.append(label)\n",
    "        augmented_signal4=shift_time(signal,sr,0.5,'right')\n",
    "        aug_data.append((augmented_signal4,sr))\n",
    "        aug_label.append(label)\n",
    "        \n",
    "#         augmented_signal4=shift_time(signal,sr,3,'right')\n",
    "#         if(label=='burping' or label=='belly_pain'):\n",
    "        augmented_signal5=random_gain(signal,0.8,1.2)\n",
    "        aug_data.append((augmented_signal5,sr))\n",
    "        aug_label.append(label)\n",
    "\n",
    "#         if(label=='burping'):\n",
    "        augmented_signal2=time_stretch(signal,0.5)\n",
    "        augmented_signal3=pitch_scale(signal,sr,2)\n",
    "#         augmented_signal6=augment_raw_audio(signal,sr)\n",
    "#         aug_data.append((augmented_signal6,sr))\n",
    "#         aug_label.append(label)\n",
    "        aug_data.append((augmented_signal2,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal3,sr))\n",
    "        aug_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count=0\n",
    "# for i in range(0,len(aug_label)):\n",
    "#     if(aug_label[i]=='discomfort' and count<6):\n",
    "#         del aug_data[i]\n",
    "#         del aug_label[i]\n",
    "#         count+=1\n",
    "#     if count==6:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features=[]\n",
    "\n",
    "def extractFeatures(X,Y):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for audio,label in zip(X,Y):\n",
    "        signal,sr=librosa.load(audio)\n",
    "        feature = featureExtractor2(signal,sr)\n",
    "        ar=np.resize(feature,(50,280))\n",
    "        x.append(ar)\n",
    "        y.append(label)\n",
    "        extracted_features.append([feature,label])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=extractFeatures(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures2(X,Y):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for audio,label in zip(X,Y):\n",
    "        singal=audio[0]\n",
    "        sr=audio[1]\n",
    "        feature = featureExtractor2(signal,sr)\n",
    "        ar=np.resize(feature,(50,280))\n",
    "        x.append(ar)\n",
    "        y.append(label)\n",
    "        extracted_features.append([feature,label])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "augX,augY=extractFeatures2(aug_data,aug_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature,label in zip(augX,augY):\n",
    "    X.append(feature)\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 75\n",
      "16 8 27 24\n"
     ]
    }
   ],
   "source": [
    "print(len(X),len(Y))\n",
    "c1=0\n",
    "c2=0\n",
    "c3=0\n",
    "c4=0\n",
    "for x in Y:\n",
    "    if(x=='belly_pain'):\n",
    "        c1+=1\n",
    "    elif x=='burping':\n",
    "        c2+=1\n",
    "    elif x=='discomfort':\n",
    "        c3+=1\n",
    "    elif x=='tired':\n",
    "        c4+=1;\n",
    "print(c1,c2,c3,c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60 15 15\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=1)\n",
    "print(len(X_train),len(y_train),len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 50, 280)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "length=len(X_train)\n",
    "X_train=np.array(X_train).reshape(length,50,280)\n",
    "y_train=np.array(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 4)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_train=to_categorical(labelencoder.fit_transform(y_train))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 50, 280)\n",
      "(15,)\n"
     ]
    }
   ],
   "source": [
    "length=len(X_test)\n",
    "X_test=np.array(X_test).reshape(length,50,280)\n",
    "y_test=np.array(y_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 4)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_test=to_categorical(labelencoder.fit_transform(y_test))\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 50, 280, 1) (15, 50, 280, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_78 (Conv2D)           (None, 48, 278, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 24, 139, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 24, 139, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 22, 137, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 11, 69, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 11, 69, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 10, 68, 32)        4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 5, 34, 32)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 5, 34, 32)         128       \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 5440)              0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 32)                174112    \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 189,380\n",
      "Trainable params: 189,188\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BUILDING MODEL\n",
    "\n",
    "import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras as keras\n",
    "from sklearn import metrics\n",
    "\n",
    "# num_labels=y.shape[1]\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model=Sequential()\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu',input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2,2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # flatten into 1D array\n",
    "    model.add(keras.layers.Flatten())\n",
    "#     model.add(keras.layers.Dense(2048,activation='relu'))\n",
    "#     model.add(keras.layers.Dense(1024,activation='relu'))\n",
    "#     model.add(keras.layers.Dense(512,activation='relu'))\n",
    "    model.add(keras.layers.Dense(32,activation='relu'))\n",
    "    model.add(keras.layers.Dense(32,activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])\n",
    "model=build_model(input_shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 611ms/step - loss: 0.7382 - acc: 0.2611 - val_loss: 1.2014 - val_acc: 0.3333\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.5641 - acc: 0.3799 - val_loss: 1.2429 - val_acc: 0.1333\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.4924 - acc: 0.4236 - val_loss: 1.0601 - val_acc: 0.1333\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 1s 333ms/step - loss: 0.4362 - acc: 0.5757 - val_loss: 0.9400 - val_acc: 0.2667\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.4144 - acc: 0.6201 - val_loss: 0.8480 - val_acc: 0.2667\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.4025 - acc: 0.6403 - val_loss: 0.7508 - val_acc: 0.4000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.3353 - acc: 0.7382 - val_loss: 0.6910 - val_acc: 0.3333\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.3390 - acc: 0.7715 - val_loss: 0.6653 - val_acc: 0.4000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.3270 - acc: 0.7938 - val_loss: 0.6402 - val_acc: 0.4667\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.3224 - acc: 0.8042 - val_loss: 0.6235 - val_acc: 0.4667\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 1s 337ms/step - loss: 0.3038 - acc: 0.7722 - val_loss: 0.6307 - val_acc: 0.4667\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.2583 - acc: 0.9132 - val_loss: 0.6502 - val_acc: 0.4667\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.2339 - acc: 0.8479 - val_loss: 0.6503 - val_acc: 0.4667\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.2152 - acc: 0.8479 - val_loss: 0.6215 - val_acc: 0.4667\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 1s 331ms/step - loss: 0.2495 - acc: 0.9125 - val_loss: 0.5886 - val_acc: 0.4667\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.2134 - acc: 0.9132 - val_loss: 0.5707 - val_acc: 0.4667\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 1s 338ms/step - loss: 0.1967 - acc: 0.9236 - val_loss: 0.5492 - val_acc: 0.5333\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 1s 343ms/step - loss: 0.1772 - acc: 0.9674 - val_loss: 0.5361 - val_acc: 0.6000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.1904 - acc: 0.8806 - val_loss: 0.5294 - val_acc: 0.6000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.1610 - acc: 0.9243 - val_loss: 0.5291 - val_acc: 0.6000\n",
      "Training completed in time:  0:00:14.349059\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "# model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "start=datetime.now()\n",
    "# history = model.fit(x_train, y_train, validation_split=0.3, epochs=10, verbose=0)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=32,epochs=20)\n",
    "\n",
    "duration=datetime.now() - start\n",
    "print(\"Training completed in time: \",duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.5291150808334351\n",
      "accuracy:  0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy= model.evaluate(X_test, y_test, verbose=0)\n",
    "# test_accuracy=model.evaluate(x_test,y_test,verbose=1)\n",
    "# print(test_accuracy[1])\n",
    "# test_accuracy\n",
    "print(\"loss: \",loss)\n",
    "# print(\"f1 score: \",f1_score)\n",
    "# print(\"precision: \",precision)\n",
    "print(\"accuracy: \",accuracy)\n",
    "# print(\"recall: \",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 22  0]\n",
      " [ 0  0  9  0]\n",
      " [ 0  0 25  1]\n",
      " [ 0  0 32  0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) \n",
    "y_pred = np.argmax(y_pred, axis = 1) \n",
    "label = np.argmax(y_test,axis = 1) \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(label,y_pred))\n",
    "# print(\"y_test:\\n\", label)\n",
    "# print(\"y_pred:\\n\",y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajeen\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort', 'tired'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label=model.predict_classes(X_test)\n",
    "print(predicted_label)\n",
    "predcited_class=labelencoder.inverse_transform(predicted_label)\n",
    "predcited_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
