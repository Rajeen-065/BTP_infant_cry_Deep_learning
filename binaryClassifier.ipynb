{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os,glob,pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, HighPassFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor(audio):\n",
    "    librosa_audio_data, librosa_sample_rate=librosa.load(audio)\n",
    "    mfccs_features= librosa.feature.mfcc(y=librosa_audio_data, sr= librosa_sample_rate,n_mfcc=50)\n",
    "    ar=np.resize(feature,(50,280))\n",
    "    ar = np.expand_dims(ar, axis=-1)\n",
    "#     mfccs_features=mfccs_features.reshape(50,280)\n",
    "#     print(librosa_sample_rate)\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor2(audio,sr):\n",
    "    mfccs_features= librosa.feature.mfcc(y=audio, sr= sr,n_mfcc=50)\n",
    "    return mfccs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "def load_data():\n",
    "    for file in glob.glob(r\"D:\\BTP\\infant cry\\donateacry_corpus_cleaned_and_updated_data\\*\"):\n",
    "        label = os.path.basename(file)\n",
    "        for audio in glob.glob(file+\"\\*.wav\"):\n",
    "            x.append(audio)\n",
    "            if label!='hungry':\n",
    "                label='nonHungry'\n",
    "            y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457 457\n"
     ]
    }
   ],
   "source": [
    "load_data()\n",
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_time(data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'both':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        if direction == 1:\n",
    "            shift = -shift\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch(signal, time_stretch_rate):\n",
    "    return librosa.effects.time_stretch(signal, time_stretch_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_scale(signal, sr, num_semitones):\n",
    "    return librosa.effects.pitch_shift(signal, sr, num_semitones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_gain(signal, min_factor=0.1, max_factor=0.12):\n",
    "    gain_rate = random.uniform(min_factor, max_factor)\n",
    "    augmented_signal = signal * gain_rate\n",
    "    return augmented_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw audio augmentation\n",
    "augment_raw_audio = Compose(\n",
    "    [\n",
    "        AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.2, p=1),\n",
    "        PitchShift(min_semitones=-8, max_semitones=8, p=1),\n",
    "        HighPassFilter(min_cutoff_freq=2000, max_cutoff_freq=4000, p=1)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data=[]\n",
    "aug_label=[]\n",
    "i=0\n",
    "for audio,label in zip(x,y):\n",
    "    if label != 'hungry':\n",
    "        signal,sr=librosa.load(audio)\n",
    "        augmented_signal1=shift_time(signal,sr,2,'both')\n",
    "        augmented_signal2=time_stretch(signal,0.5)\n",
    "        augmented_signal3=pitch_scale(signal,sr,2)\n",
    "#         augmented_signal4=shift_time(signal,sr,3,'right')\n",
    "        augmented_signal5=random_gain(signal,2,4)\n",
    "        augmented_signal6=augment_raw_audio(signal,sr)\n",
    "        \n",
    "        aug_data.append((augmented_signal1,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal2,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal3,sr))\n",
    "#         aug_label.append(label)\n",
    "#         aug_data.append((augmented_signal4,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal5,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal6,sr))\n",
    "        aug_label.append(label)\n",
    "#         sf.write(\"augmented_signal1.wav\", augmented_signal, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features=[]\n",
    "\n",
    "def extractFeatures(X,Y):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for audio,label in zip(X,Y):\n",
    "        signal,sr=librosa.load(audio)\n",
    "        feature = featureExtractor2(signal,sr)\n",
    "        ar=np.resize(feature,(50,280))\n",
    "        x.append(ar)\n",
    "        y.append(label)\n",
    "        extracted_features.append([feature,label])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=extractFeatures(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures2(X,Y):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for audio,label in zip(X,Y):\n",
    "        singal=audio[0]\n",
    "        sr=audio[1]\n",
    "        feature = featureExtractor2(signal,sr)\n",
    "        ar=np.resize(feature,(50,280))\n",
    "        x.append(ar)\n",
    "        y.append(label)\n",
    "        extracted_features.append([feature,label])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "augX,augY=extractFeatures2(aug_data,aug_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature,label in zip(augX,augY):\n",
    "    X.append(feature)\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832 832\n"
     ]
    }
   ],
   "source": [
    "print(len(X),len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665 665 167 167\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "print(len(X_train),len(y_train),len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 50, 280)\n",
      "(665,)\n"
     ]
    }
   ],
   "source": [
    "length=len(X_train)\n",
    "X_train=np.array(X_train).reshape(length,50,280)\n",
    "y_train=np.array(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_train=to_categorical(labelencoder.fit_transform(y_train))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 50, 280)\n",
      "(167,)\n"
     ]
    }
   ],
   "source": [
    "length=len(X_test)\n",
    "X_test=np.array(X_test).reshape(length,50,280)\n",
    "y_test=np.array(y_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_test=to_categorical(labelencoder.fit_transform(y_test))\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 50, 280, 1) (167, 50, 280, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 48, 278, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 24, 139, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 24, 139, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 22, 137, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 11, 69, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 11, 69, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 10, 68, 32)        4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 34, 32)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 5, 34, 32)         128       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 5440)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                348224    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 362,434\n",
      "Trainable params: 362,242\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BUILDING MODEL\n",
    "\n",
    "import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras as keras\n",
    "from sklearn import metrics\n",
    "\n",
    "# num_labels=y.shape[1]\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model=Sequential()\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu',input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2,2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # flatten into 1D array\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64,activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(2))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])\n",
    "model=build_model(input_shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "# def f1_m(y_true, y_pred):\n",
    "#     precision = precision_m(y_true, y_pred)\n",
    "#     recall = recall_m(y_true, y_pred)\n",
    "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "21/21 [==============================] - 12s 489ms/step - loss: 0.0188 - acc: 0.9945 - val_loss: 0.5111 - val_acc: 0.9102\n",
      "Epoch 2/15\n",
      "21/21 [==============================] - 9s 436ms/step - loss: 0.0283 - acc: 0.9895 - val_loss: 0.5310 - val_acc: 0.9102\n",
      "Epoch 3/15\n",
      "21/21 [==============================] - 10s 469ms/step - loss: 0.0264 - acc: 0.9901 - val_loss: 0.5579 - val_acc: 0.9042\n",
      "Epoch 4/15\n",
      "21/21 [==============================] - 9s 428ms/step - loss: 0.0244 - acc: 0.9889 - val_loss: 0.4479 - val_acc: 0.9102\n",
      "Epoch 5/15\n",
      "21/21 [==============================] - 9s 452ms/step - loss: 0.0113 - acc: 0.9990 - val_loss: 0.5369 - val_acc: 0.9102\n",
      "Epoch 6/15\n",
      "21/21 [==============================] - 9s 448ms/step - loss: 0.0175 - acc: 0.9932 - val_loss: 0.5090 - val_acc: 0.9162\n",
      "Epoch 7/15\n",
      "21/21 [==============================] - 10s 468ms/step - loss: 0.0188 - acc: 0.9950 - val_loss: 0.5665 - val_acc: 0.9162\n",
      "Epoch 8/15\n",
      "21/21 [==============================] - 10s 462ms/step - loss: 0.0234 - acc: 0.9929 - val_loss: 0.5903 - val_acc: 0.9162\n",
      "Epoch 9/15\n",
      "21/21 [==============================] - 10s 463ms/step - loss: 0.0077 - acc: 0.9960 - val_loss: 0.6426 - val_acc: 0.9102\n",
      "Epoch 10/15\n",
      "21/21 [==============================] - 10s 454ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6110 - val_acc: 0.8982\n",
      "Epoch 11/15\n",
      "21/21 [==============================] - 9s 452ms/step - loss: 0.0131 - acc: 0.9938 - val_loss: 0.6877 - val_acc: 0.9162\n",
      "Epoch 12/15\n",
      "21/21 [==============================] - 10s 468ms/step - loss: 0.0160 - acc: 0.9921 - val_loss: 0.5889 - val_acc: 0.9162\n",
      "Epoch 13/15\n",
      "21/21 [==============================] - 10s 466ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.5855 - val_acc: 0.9102\n",
      "Epoch 14/15\n",
      "21/21 [==============================] - 9s 449ms/step - loss: 0.0039 - acc: 0.9985 - val_loss: 0.5229 - val_acc: 0.8802\n",
      "Epoch 15/15\n",
      "21/21 [==============================] - 10s 469ms/step - loss: 0.0173 - acc: 0.9948 - val_loss: 0.6930 - val_acc: 0.9162\n",
      "Training completed in time:  0:02:26.307958\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "# model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "start=datetime.now()\n",
    "# history = model.fit(x_train, y_train, validation_split=0.3, epochs=10, verbose=0)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=32,epochs=15)\n",
    "\n",
    "duration=datetime.now() - start\n",
    "print(\"Training completed in time: \",duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.6930208206176758\n",
      "f1 score:  0.9273236393928528\n",
      "accuracy:  0.916167676448822\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy= model.evaluate(X_test, y_test, verbose=0)\n",
    "# test_accuracy=model.evaluate(x_test,y_test,verbose=1)\n",
    "# print(test_accuracy[1])\n",
    "# test_accuracy\n",
    "print(\"loss: \",loss)\n",
    "print(\"f1 score: \",f1_score)\n",
    "# print(\"precision: \",precision)\n",
    "print(\"accuracy: \",accuracy)\n",
    "# print(\"recall: \",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  1]\n",
      " [13 86]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) \n",
    "y_pred = np.argmax(y_pred, axis = 1) \n",
    "label = np.argmax(y_test,axis = 1) \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(label,y_pred))\n",
    "# print(\"y_test:\\n\", label)\n",
    "# print(\"y_pred:\\n\",y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = tf.keras.models.load_model(\"models/model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 280, 1)\n"
     ]
    }
   ],
   "source": [
    "filename='discomfort.wav'\n",
    "prediction_feature=featureExtractor(filename)\n",
    "prediction_feature=prediction_feature.reshape(-1,50,280,1)\n",
    "print(prediction_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['nonHungry'], dtype='<U9')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model.predict_classes(prediction_feature)\n",
    "predicted_label=model.predict_classes(prediction_feature)\n",
    "print(predicted_label)\n",
    "predcited_class=labelencoder.inverse_transform(predicted_label)\n",
    "predcited_class\n",
    "# model.predict('/hungry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
