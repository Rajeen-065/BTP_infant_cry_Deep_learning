{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os,glob,pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, HighPassFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor(audio):\n",
    "    librosa_audio_data, librosa_sample_rate=librosa.load(audio)\n",
    "    mfccs_features= librosa.feature.mfcc(y=librosa_audio_data, sr= librosa_sample_rate,n_mfcc=50)\n",
    "    ar=np.resize(feature,(50,280))\n",
    "    ar = np.expand_dims(ar, axis=-1)\n",
    "#     mfccs_features=mfccs_features.reshape(50,280)\n",
    "#     print(librosa_sample_rate)\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor2(audio,sr):\n",
    "    mfccs_features= librosa.feature.mfcc(y=audio, sr= sr,n_mfcc=50)\n",
    "    return mfccs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "def load_data():\n",
    "    for file in glob.glob(r\"D:\\BTP\\infant cry\\donateacry_corpus_cleaned_and_updated_data\\*\"):\n",
    "        label = os.path.basename(file)\n",
    "        for audio in glob.glob(file+\"\\*.wav\"):\n",
    "            x.append(audio)\n",
    "            if label!='hungry':\n",
    "                label='nonHungry'\n",
    "            y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457 457\n"
     ]
    }
   ],
   "source": [
    "load_data()\n",
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_time(data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'both':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        if direction == 1:\n",
    "            shift = -shift\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch(signal, time_stretch_rate):\n",
    "    return librosa.effects.time_stretch(signal, time_stretch_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_scale(signal, sr, num_semitones):\n",
    "    return librosa.effects.pitch_shift(signal, sr, num_semitones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_gain(signal, min_factor=0.1, max_factor=0.12):\n",
    "    gain_rate = random.uniform(min_factor, max_factor)\n",
    "    augmented_signal = signal * gain_rate\n",
    "    return augmented_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw audio augmentation\n",
    "augment_raw_audio = Compose(\n",
    "    [\n",
    "        AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.2, p=1),\n",
    "        PitchShift(min_semitones=-8, max_semitones=8, p=1),\n",
    "        HighPassFilter(min_cutoff_freq=2000, max_cutoff_freq=4000, p=1)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data=[]\n",
    "aug_label=[]\n",
    "i=0\n",
    "for audio,label in zip(x,y):\n",
    "    if label != 'hungry':\n",
    "        signal,sr=librosa.load(audio)\n",
    "        augmented_signal1=shift_time(signal,sr,2,'both')\n",
    "        augmented_signal2=time_stretch(signal,0.5)\n",
    "        augmented_signal3=pitch_scale(signal,sr,2)\n",
    "#         augmented_signal4=shift_time(signal,sr,3,'right')\n",
    "        augmented_signal5=random_gain(signal,2,4)\n",
    "        augmented_signal6=augment_raw_audio(signal,sr)\n",
    "        \n",
    "        aug_data.append((augmented_signal1,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal2,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal3,sr))\n",
    "#         aug_label.append(label)\n",
    "#         aug_data.append((augmented_signal4,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal5,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal6,sr))\n",
    "        aug_label.append(label)\n",
    "#         sf.write(\"augmented_signal1.wav\", augmented_signal, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features=[]\n",
    "\n",
    "def extractFeatures(X,Y):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for audio,label in zip(X,Y):\n",
    "        signal,sr=librosa.load(audio)\n",
    "        feature = featureExtractor2(signal,sr)\n",
    "        ar=np.resize(feature,(50,280))\n",
    "        x.append(ar)\n",
    "        y.append(label)\n",
    "        extracted_features.append([feature,label])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=extractFeatures(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures2(X,Y):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for audio,label in zip(X,Y):\n",
    "        singal=audio[0]\n",
    "        sr=audio[1]\n",
    "        feature = featureExtractor2(signal,sr)\n",
    "        ar=np.resize(feature,(50,280))\n",
    "        x.append(ar)\n",
    "        y.append(label)\n",
    "        extracted_features.append([feature,label])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "augX,augY=extractFeatures2(aug_data,aug_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature,label in zip(augX,augY):\n",
    "    X.append(feature)\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832 832\n"
     ]
    }
   ],
   "source": [
    "print(len(X),len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665 665 167 167\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "print(len(X_train),len(y_train),len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 50, 280)\n",
      "(665,)\n"
     ]
    }
   ],
   "source": [
    "length=len(X_train)\n",
    "X_train=np.array(X_train).reshape(length,50,280)\n",
    "y_train=np.array(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_train=to_categorical(labelencoder.fit_transform(y_train))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 50, 280)\n",
      "(167,)\n"
     ]
    }
   ],
   "source": [
    "length=len(X_test)\n",
    "X_test=np.array(X_test).reshape(length,50,280)\n",
    "y_test=np.array(y_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_test=to_categorical(labelencoder.fit_transform(y_test))\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 50, 280, 1) (167, 50, 280, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 48, 278, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 24, 139, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 24, 139, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 22, 137, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 11, 69, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 11, 69, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 10, 68, 32)        4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 5, 34, 32)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 5, 34, 32)         128       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5440)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                87056     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 101,170\n",
      "Trainable params: 100,978\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BUILDING MODEL\n",
    "\n",
    "import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras as keras\n",
    "from sklearn import metrics\n",
    "\n",
    "# num_labels=y.shape[1]\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model=Sequential()\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu',input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2,2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # flatten into 1D array\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(16,activation='relu'))\n",
    "#     model.add(keras.layers.Dense(32,activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(2))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])\n",
    "model=build_model(input_shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "# def f1_m(y_true, y_pred):\n",
    "#     precision = precision_m(y_true, y_pred)\n",
    "#     recall = recall_m(y_true, y_pred)\n",
    "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "21/21 [==============================] - 8s 325ms/step - loss: 0.7082 - acc: 0.7248 - val_loss: 0.8347 - val_acc: 0.6407\n",
      "Epoch 2/13\n",
      "21/21 [==============================] - 7s 323ms/step - loss: 0.5698 - acc: 0.8333 - val_loss: 0.6511 - val_acc: 0.8982\n",
      "Epoch 3/13\n",
      "21/21 [==============================] - 7s 319ms/step - loss: 0.5399 - acc: 0.8457 - val_loss: 0.6143 - val_acc: 0.8743\n",
      "Epoch 4/13\n",
      "21/21 [==============================] - 7s 322ms/step - loss: 0.2722 - acc: 0.8735 - val_loss: 0.4569 - val_acc: 0.8683\n",
      "Epoch 5/13\n",
      "21/21 [==============================] - 7s 317ms/step - loss: 0.2590 - acc: 0.9129 - val_loss: 0.3232 - val_acc: 0.9102\n",
      "Epoch 6/13\n",
      "21/21 [==============================] - 7s 317ms/step - loss: 0.2315 - acc: 0.9370 - val_loss: 0.3447 - val_acc: 0.8443\n",
      "Epoch 7/13\n",
      "21/21 [==============================] - 6s 308ms/step - loss: 0.2088 - acc: 0.9420 - val_loss: 0.2871 - val_acc: 0.8743\n",
      "Epoch 8/13\n",
      "21/21 [==============================] - 7s 314ms/step - loss: 0.1713 - acc: 0.9552 - val_loss: 0.2795 - val_acc: 0.9102\n",
      "Epoch 9/13\n",
      "21/21 [==============================] - 6s 306ms/step - loss: 0.1612 - acc: 0.9595 - val_loss: 0.2669 - val_acc: 0.9102\n",
      "Epoch 10/13\n",
      "21/21 [==============================] - 7s 319ms/step - loss: 0.1818 - acc: 0.9527 - val_loss: 0.2683 - val_acc: 0.9102\n",
      "Epoch 11/13\n",
      "21/21 [==============================] - 6s 302ms/step - loss: 0.1683 - acc: 0.9519 - val_loss: 0.2765 - val_acc: 0.9102\n",
      "Epoch 12/13\n",
      "21/21 [==============================] - 6s 311ms/step - loss: 0.1436 - acc: 0.9573 - val_loss: 0.3239 - val_acc: 0.9102\n",
      "Epoch 13/13\n",
      "21/21 [==============================] - 7s 313ms/step - loss: 0.1498 - acc: 0.9696 - val_loss: 0.2905 - val_acc: 0.9102\n",
      "Training completed in time:  0:01:26.775566\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "# model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "start=datetime.now()\n",
    "# history = model.fit(x_train, y_train, validation_split=0.3, epochs=10, verbose=0)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=32,epochs=13)\n",
    "\n",
    "duration=datetime.now() - start\n",
    "print(\"Training completed in time: \",duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.2604829967021942\n",
      "accuracy:  0.8922155499458313\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy= model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"loss: \",loss)\n",
    "print(\"accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62  6]\n",
      " [12 87]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) \n",
    "y_pred = np.argmax(y_pred, axis = 1) \n",
    "label = np.argmax(y_test,axis = 1) \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(label,y_pred))\n",
    "# print(\"y_test:\\n\", label)\n",
    "# print(\"y_pred:\\n\",y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = tf.keras.models.load_model(\"models/model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87        68\n",
      "           1       0.94      0.88      0.91        99\n",
      "\n",
      "    accuracy                           0.89       167\n",
      "   macro avg       0.89      0.90      0.89       167\n",
      "weighted avg       0.90      0.89      0.89       167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,f1_score\n",
    "print(classification_report(y_true=label,y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1-score per class:  [0.87323944 0.90625   ]\n",
      "The f1-score :  0.8928085729948555\n"
     ]
    }
   ],
   "source": [
    "f1_score_per_class_validation = f1_score(y_true=label,y_pred=y_pred,average=None) \n",
    "print(\"The f1-score per class: \",f1_score_per_class_validation)\n",
    "print(\"The f1-score : \",f1_score(y_true=label,y_pred=y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
