{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os,glob,pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, HighPassFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor(audio):\n",
    "    librosa_audio_data, librosa_sample_rate=librosa.load(audio)\n",
    "    mfccs_features= librosa.feature.mfcc(y=librosa_audio_data, sr= librosa_sample_rate,n_mfcc=50)\n",
    "#     print(librosa_sample_rate)\n",
    "    return mfccs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor2(audio,sr):\n",
    "    mfccs_features= librosa.feature.mfcc(y=audio, sr= sr,n_mfcc=50)\n",
    "    return mfccs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "def load_data():\n",
    "    for file in glob.glob(r\"D:\\BTP\\infant cry\\donateacry_corpus_cleaned_and_updated_data\\*\"):\n",
    "        label = os.path.basename(file)\n",
    "        for audio in glob.glob(file+\"\\*.wav\"):\n",
    "            x.append(audio)\n",
    "            y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457 457\n"
     ]
    }
   ],
   "source": [
    "load_data()\n",
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 365 92 92\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "print(len(X_train),len(y_train),len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_noise(signal, noise_percentage_factor):\n",
    "#     noise = np.random.normal(0, signal.std(), signal.size)\n",
    "#     augmented_signal = signal + noise * noise_percentage_factor\n",
    "#     return augmented_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_time(data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'both':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        if direction == 1:\n",
    "            shift = -shift\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch(signal, time_stretch_rate):\n",
    "    return librosa.effects.time_stretch(signal, time_stretch_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_scale(signal, sr, num_semitones):\n",
    "    return librosa.effects.pitch_shift(signal, sr, num_semitones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_gain(signal, min_factor=0.1, max_factor=0.12):\n",
    "    gain_rate = random.uniform(min_factor, max_factor)\n",
    "    augmented_signal = signal * gain_rate\n",
    "    return augmented_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def invert_polarity(signal):\n",
    "#     return signal * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw audio augmentation\n",
    "augment_raw_audio = Compose(\n",
    "    [\n",
    "        AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.2, p=1),\n",
    "        PitchShift(min_semitones=-8, max_semitones=8, p=1),\n",
    "        HighPassFilter(min_cutoff_freq=2000, max_cutoff_freq=4000, p=1)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data=[]\n",
    "aug_label=[]\n",
    "i=0\n",
    "for audio,label in zip(X_train,y_train):\n",
    "    if label != 'hungry':\n",
    "        signal,sr=librosa.load(audio)\n",
    "        augmented_signal1=shift_time(signal,sr,2,'both')\n",
    "        augmented_signal2=time_stretch(signal,0.5)\n",
    "        augmented_signal3=pitch_scale(signal,sr,2)\n",
    "        augmented_signal4=shift_time(signal,sr,3,'right')\n",
    "        augmented_signal5=random_gain(signal,2,4)\n",
    "        augmented_signal6=augment_raw_audio(signal,sr)\n",
    "        \n",
    "        aug_data.append((augmented_signal1,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal2,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal3,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal4,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal5,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal6,sr))\n",
    "        aug_label.append(label)\n",
    "#         sf.write(\"augmented_signal1.wav\", augmented_signal, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372 372\n"
     ]
    }
   ],
   "source": [
    "print(len(aug_data),len(aug_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features=[]\n",
    "\n",
    "def extractFeatures(X,Y):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for audio,label in zip(X,Y):\n",
    "        signal,sr=librosa.load(audio)\n",
    "        feature = featureExtractor2(signal,sr)\n",
    "        ar=np.resize(feature,(50,280))\n",
    "        x.append(ar)\n",
    "        y.append(label)\n",
    "        extracted_features.append([feature,label])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=extractFeatures(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test=extractFeatures(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures2(X,Y):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for audio,label in zip(X,Y):\n",
    "        singal=audio[0]\n",
    "        sr=audio[1]\n",
    "        feature = featureExtractor2(signal,sr)\n",
    "        ar=np.resize(feature,(50,280))\n",
    "        x.append(ar)\n",
    "        y.append(label)\n",
    "        extracted_features.append([feature,label])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "augX,augY=extractFeatures2(aug_data,aug_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(50, 280) (50, 280)\n",
      "<class 'list'> <class 'list'>\n",
      "<class 'str'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train),type(augX))\n",
    "print(type(x_train[0]),type(augX[0]))\n",
    "print(x_train[0].shape,augX[0].shape)\n",
    "print(type(y_train),type(augY))\n",
    "print(type(y_train[0]),type(augY[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature,label in zip(augX,augY):\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(x_train))\n",
    "# print(type(y_train))\n",
    "# print(len(x_train))\n",
    "# print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737, 50, 280)\n",
      "(737,)\n"
     ]
    }
   ],
   "source": [
    "length=len(x_train)\n",
    "x_train=np.array(x_train).reshape(length,50,280)\n",
    "y_train=np.array(y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_train=to_categorical(labelencoder.fit_transform(y_train))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x_test))\n",
    "# print(x_test[0].shape)\n",
    "# print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 50, 280)\n",
      "(92,)\n"
     ]
    }
   ],
   "source": [
    "x_test=np.array(x_test).reshape(92,50,280)\n",
    "y_test=np.array(y_test)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_test=to_categorical(labelencoder.fit_transform(y_test))\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737, 50, 280, 1) (92, 50, 280, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 278, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 139, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 24, 139, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 137, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 69, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 69, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 68, 32)        4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 34, 32)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 34, 32)         128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5440)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                348224    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 362,629\n",
      "Trainable params: 362,437\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BUILDING MODEL\n",
    "\n",
    "import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras as keras\n",
    "from sklearn import metrics\n",
    "\n",
    "# num_labels=y.shape[1]\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model=Sequential()\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu',input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2,2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization()) \n",
    "\n",
    "    # flatten into 1D array\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64,activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "input_shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3])\n",
    "model=build_model(input_shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import backend as K\n",
    "\n",
    "# def recall_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     return recall\n",
    "\n",
    "# def precision_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     return precision\n",
    "\n",
    "# def f1_m(y_true, y_pred):\n",
    "#     precision = precision_m(y_true, y_pred)\n",
    "#     recall = recall_m(y_true, y_pred)\n",
    "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "24/24 [==============================] - 16s 579ms/step - loss: 0.6658 - acc: 0.4530 - val_loss: 0.6093 - val_acc: 0.6739\n",
      "Epoch 2/15\n",
      "24/24 [==============================] - 10s 429ms/step - loss: 0.4320 - acc: 0.5446 - val_loss: 0.2587 - val_acc: 0.8587\n",
      "Epoch 3/15\n",
      "24/24 [==============================] - 10s 430ms/step - loss: 0.3964 - acc: 0.5650 - val_loss: 0.2687 - val_acc: 0.8587\n",
      "Epoch 4/15\n",
      "24/24 [==============================] - 10s 420ms/step - loss: 0.3760 - acc: 0.6180 - val_loss: 0.2436 - val_acc: 0.8587\n",
      "Epoch 5/15\n",
      "24/24 [==============================] - 10s 423ms/step - loss: 0.3610 - acc: 0.5913 - val_loss: 0.2197 - val_acc: 0.8587\n",
      "Epoch 6/15\n",
      "24/24 [==============================] - 9s 371ms/step - loss: 0.3388 - acc: 0.5888 - val_loss: 0.2287 - val_acc: 0.8587\n",
      "Epoch 7/15\n",
      "24/24 [==============================] - 7s 303ms/step - loss: 0.3306 - acc: 0.5849 - val_loss: 0.2123 - val_acc: 0.8587\n",
      "Epoch 8/15\n",
      "24/24 [==============================] - 7s 302ms/step - loss: 0.3370 - acc: 0.6132 - val_loss: 0.2127 - val_acc: 0.8587\n",
      "Epoch 9/15\n",
      "24/24 [==============================] - 7s 306ms/step - loss: 0.3215 - acc: 0.6338 - val_loss: 0.2229 - val_acc: 0.8587\n",
      "Epoch 10/15\n",
      "24/24 [==============================] - 7s 309ms/step - loss: 0.3004 - acc: 0.6680 - val_loss: 0.2514 - val_acc: 0.8587\n",
      "Epoch 11/15\n",
      "24/24 [==============================] - 7s 311ms/step - loss: 0.3179 - acc: 0.6394 - val_loss: 0.2307 - val_acc: 0.8587\n",
      "Epoch 12/15\n",
      "24/24 [==============================] - 7s 302ms/step - loss: 0.3133 - acc: 0.6506 - val_loss: 0.2984 - val_acc: 0.8587\n",
      "Epoch 13/15\n",
      "24/24 [==============================] - 7s 304ms/step - loss: 0.2881 - acc: 0.6737 - val_loss: 0.2903 - val_acc: 0.8587\n",
      "Epoch 14/15\n",
      "24/24 [==============================] - 7s 301ms/step - loss: 0.2891 - acc: 0.6780 - val_loss: 0.2838 - val_acc: 0.8587\n",
      "Epoch 15/15\n",
      "24/24 [==============================] - 7s 278ms/step - loss: 0.2817 - acc: 0.6696 - val_loss: 0.2961 - val_acc: 0.8587\n",
      "Training completed in time:  0:02:11.633186\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "# model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "start=datetime.now()\n",
    "# history = model.fit(x_train, y_train, validation_split=0.3, epochs=10, verbose=0)\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=32,epochs=15)\n",
    "\n",
    "duration=datetime.now() - start\n",
    "print(\"Training completed in time: \",duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.2961154282093048\n",
      "accuracy:  0.8586956262588501\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "# test_accuracy=model.evaluate(x_test,y_test,verbose=1)\n",
    "# print(test_accuracy[1])\n",
    "# test_accuracy\n",
    "print(\"loss: \",loss)\n",
    "print(\"accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  5  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 0  0  0 79  0]\n",
      " [ 0  0  0  6  0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test) \n",
    "y_pred = np.argmax(y_pred, axis = 1) \n",
    "label = np.argmax(y_test,axis = 1) \n",
    "\n",
    "# print(pred.shape)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(label,y_pred))\n",
    "# print(\"y_test:\\n\", label)\n",
    "# print(\"y_pred:\\n\",y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.86      1.00      0.92        79\n",
      "           4       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.86        92\n",
      "   macro avg       0.17      0.20      0.18        92\n",
      "weighted avg       0.74      0.86      0.79        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,f1_score\n",
    "print(classification_report(y_true=label,y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1-score per class:  [0.         0.         0.         0.92397661 0.        ]\n",
      "The f1-score :  0.7934146961606916\n"
     ]
    }
   ],
   "source": [
    "f1_score_per_class_validation = f1_score(y_true=label,y_pred=y_pred,average=None) \n",
    "print(\"The f1-score per class: \",f1_score_per_class_validation)\n",
    "print(\"The f1-score : \",f1_score(y_true=label,y_pred=y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
