{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os,glob,pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, HighPassFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor(audio):\n",
    "    librosa_audio_data, librosa_sample_rate=librosa.load(audio)\n",
    "    mfccs_features= librosa.feature.mfcc(y=librosa_audio_data, sr= librosa_sample_rate,n_mfcc=50)\n",
    "#     print(librosa_sample_rate)\n",
    "    return mfccs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor2(audio,sr):\n",
    "    mfccs_features= librosa.feature.mfcc(y=audio, sr= sr,n_mfcc=50)\n",
    "    return mfccs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "def load_data():\n",
    "    for file in glob.glob(r\"D:\\BTP\\infant cry\\donateacry_corpus_cleaned_and_updated_data\\*\"):\n",
    "        label = os.path.basename(file)\n",
    "        for audio in glob.glob(file+\"\\*.wav\"):\n",
    "            x.append(audio)\n",
    "            y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457 457\n"
     ]
    }
   ],
   "source": [
    "load_data()\n",
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 365 92 92\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "print(len(X_train),len(y_train),len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_noise(signal, noise_percentage_factor):\n",
    "#     noise = np.random.normal(0, signal.std(), signal.size)\n",
    "#     augmented_signal = signal + noise * noise_percentage_factor\n",
    "#     return augmented_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_time(data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'both':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        if direction == 1:\n",
    "            shift = -shift\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch(signal, time_stretch_rate):\n",
    "    return librosa.effects.time_stretch(signal, time_stretch_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_scale(signal, sr, num_semitones):\n",
    "    return librosa.effects.pitch_shift(signal, sr, num_semitones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_gain(signal, min_factor=0.1, max_factor=0.12):\n",
    "    gain_rate = random.uniform(min_factor, max_factor)\n",
    "    augmented_signal = signal * gain_rate\n",
    "    return augmented_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def invert_polarity(signal):\n",
    "#     return signal * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw audio augmentation\n",
    "augment_raw_audio = Compose(\n",
    "    [\n",
    "        AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.2, p=1),\n",
    "        PitchShift(min_semitones=-8, max_semitones=8, p=1),\n",
    "        HighPassFilter(min_cutoff_freq=2000, max_cutoff_freq=4000, p=1)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data=[]\n",
    "aug_label=[]\n",
    "i=0\n",
    "for audio,label in zip(X_train,y_train):\n",
    "    if label != 'hungry':\n",
    "        signal,sr=librosa.load(audio)\n",
    "        augmented_signal1=shift_time(signal,sr,2,'both')\n",
    "        augmented_signal2=time_stretch(signal,0.5)\n",
    "        augmented_signal3=pitch_scale(signal,sr,2)\n",
    "        augmented_signal4=shift_time(signal,sr,3,'right')\n",
    "        augmented_signal5=random_gain(signal,2,4)\n",
    "        augmented_signal6=augment_raw_audio(signal,sr)\n",
    "        \n",
    "        aug_data.append((augmented_signal1,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal2,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal3,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal4,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal5,sr))\n",
    "        aug_label.append(label)\n",
    "        aug_data.append((augmented_signal6,sr))\n",
    "        aug_label.append(label)\n",
    "#         sf.write(\"augmented_signal1.wav\", augmented_signal, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372 372\n"
     ]
    }
   ],
   "source": [
    "print(len(aug_data),len(aug_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features=[]\n",
    "\n",
    "def extractFeatures(X,Y):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for audio,label in zip(X,Y):\n",
    "        signal,sr=librosa.load(audio)\n",
    "        feature = featureExtractor2(signal,sr)\n",
    "        ar=np.resize(feature,(50,280))\n",
    "        x.append(ar)\n",
    "        y.append(label)\n",
    "        extracted_features.append([feature,label])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=extractFeatures(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test=extractFeatures(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures2(X,Y):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for audio,label in zip(X,Y):\n",
    "        singal=audio[0]\n",
    "        sr=audio[1]\n",
    "        feature = featureExtractor2(signal,sr)\n",
    "        ar=np.resize(feature,(50,280))\n",
    "        x.append(ar)\n",
    "        y.append(label)\n",
    "        extracted_features.append([feature,label])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "augX,augY=extractFeatures2(aug_data,aug_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(50, 280) (50, 280)\n",
      "<class 'list'> <class 'list'>\n",
      "<class 'str'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train),type(augX))\n",
    "print(type(x_train[0]),type(augX[0]))\n",
    "print(x_train[0].shape,augX[0].shape)\n",
    "print(type(y_train),type(augY))\n",
    "print(type(y_train[0]),type(augY[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature,label in zip(augX,augY):\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(x_train))\n",
    "# print(type(y_train))\n",
    "# print(len(x_train))\n",
    "# print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737, 50, 280)\n",
      "(737,)\n"
     ]
    }
   ],
   "source": [
    "length=len(x_train)\n",
    "x_train=np.array(x_train).reshape(length,50,280)\n",
    "y_train=np.array(y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_train=to_categorical(labelencoder.fit_transform(y_train))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x_test))\n",
    "# print(x_test[0].shape)\n",
    "# print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 50, 280)\n",
      "(92,)\n"
     ]
    }
   ],
   "source": [
    "x_test=np.array(x_test).reshape(92,50,280)\n",
    "y_test=np.array(y_test)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_test=to_categorical(labelencoder.fit_transform(y_test))\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737, 50, 280, 1) (92, 50, 280, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 278, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 139, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 24, 139, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 137, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 69, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 69, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 68, 32)        4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 34, 32)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 34, 32)         128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5440)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                348224    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 362,629\n",
      "Trainable params: 362,437\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BUILDING MODEL\n",
    "\n",
    "import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras as keras\n",
    "from sklearn import metrics\n",
    "\n",
    "# num_labels=y.shape[1]\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model=Sequential()\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu',input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2,2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # flatten into 1D array\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64,activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "input_shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3])\n",
    "model=build_model(input_shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "24/24 [==============================] - 10s 334ms/step - loss: 0.3902 - acc: 0.6311 - f1_m: 0.5888 - precision_m: 0.9066 - recall_m: 0.4414 - val_loss: 0.3128 - val_acc: 0.8261 - val_f1_m: 0.8292 - val_precision_m: 0.8341 - val_recall_m: 0.8244\n",
      "Epoch 2/15\n",
      "24/24 [==============================] - 8s 316ms/step - loss: 0.3362 - acc: 0.6906 - f1_m: 0.6275 - precision_m: 0.7851 - recall_m: 0.5291 - val_loss: 0.4380 - val_acc: 0.8587 - val_f1_m: 0.8586 - val_precision_m: 0.8586 - val_recall_m: 0.8586\n",
      "Epoch 3/15\n",
      "24/24 [==============================] - 7s 300ms/step - loss: 0.3372 - acc: 0.6521 - f1_m: 0.6346 - precision_m: 0.8594 - recall_m: 0.5144 - val_loss: 0.3350 - val_acc: 0.8478 - val_f1_m: 0.8517 - val_precision_m: 0.8569 - val_recall_m: 0.8467\n",
      "Epoch 4/15\n",
      "24/24 [==============================] - 8s 316ms/step - loss: 0.2991 - acc: 0.6916 - f1_m: 0.6400 - precision_m: 0.8119 - recall_m: 0.5353 - val_loss: 0.4089 - val_acc: 0.8587 - val_f1_m: 0.8586 - val_precision_m: 0.8586 - val_recall_m: 0.8586\n",
      "Epoch 5/15\n",
      "24/24 [==============================] - 7s 295ms/step - loss: 0.2999 - acc: 0.6713 - f1_m: 0.6060 - precision_m: 0.7624 - recall_m: 0.5073 - val_loss: 0.3733 - val_acc: 0.8587 - val_f1_m: 0.8586 - val_precision_m: 0.8586 - val_recall_m: 0.8586\n",
      "Epoch 6/15\n",
      "24/24 [==============================] - 8s 314ms/step - loss: 0.2807 - acc: 0.6954 - f1_m: 0.6670 - precision_m: 0.7926 - recall_m: 0.5779 - val_loss: 0.4026 - val_acc: 0.8587 - val_f1_m: 0.8517 - val_precision_m: 0.8569 - val_recall_m: 0.8467\n",
      "Epoch 7/15\n",
      "24/24 [==============================] - 7s 305ms/step - loss: 0.2948 - acc: 0.6587 - f1_m: 0.6329 - precision_m: 0.8773 - recall_m: 0.4989 - val_loss: 0.4326 - val_acc: 0.8587 - val_f1_m: 0.8586 - val_precision_m: 0.8586 - val_recall_m: 0.8586\n",
      "Epoch 8/15\n",
      "24/24 [==============================] - 7s 280ms/step - loss: 0.2807 - acc: 0.6829 - f1_m: 0.6284 - precision_m: 0.8168 - recall_m: 0.5151 - val_loss: 0.3823 - val_acc: 0.8478 - val_f1_m: 0.8341 - val_precision_m: 0.8446 - val_recall_m: 0.8244\n",
      "Epoch 9/15\n",
      "24/24 [==============================] - 8s 327ms/step - loss: 0.2600 - acc: 0.7084 - f1_m: 0.6797 - precision_m: 0.8824 - recall_m: 0.5578 - val_loss: 0.4622 - val_acc: 0.8478 - val_f1_m: 0.8482 - val_precision_m: 0.8482 - val_recall_m: 0.8482\n",
      "Epoch 10/15\n",
      "24/24 [==============================] - 7s 293ms/step - loss: 0.2784 - acc: 0.6676 - f1_m: 0.6137 - precision_m: 0.8537 - recall_m: 0.4850 - val_loss: 0.3545 - val_acc: 0.8370 - val_f1_m: 0.8360 - val_precision_m: 0.8449 - val_recall_m: 0.8274\n",
      "Epoch 11/15\n",
      "24/24 [==============================] - 7s 296ms/step - loss: 0.2933 - acc: 0.6720 - f1_m: 0.6170 - precision_m: 0.8389 - recall_m: 0.4900 - val_loss: 0.3821 - val_acc: 0.8043 - val_f1_m: 0.8042 - val_precision_m: 0.8126 - val_recall_m: 0.7961\n",
      "Epoch 12/15\n",
      "24/24 [==============================] - 9s 354ms/step - loss: 0.2781 - acc: 0.6961 - f1_m: 0.6529 - precision_m: 0.8674 - recall_m: 0.5293 - val_loss: 0.4169 - val_acc: 0.8587 - val_f1_m: 0.8586 - val_precision_m: 0.8586 - val_recall_m: 0.8586\n",
      "Epoch 13/15\n",
      "24/24 [==============================] - 7s 299ms/step - loss: 0.2862 - acc: 0.6617 - f1_m: 0.6120 - precision_m: 0.8838 - recall_m: 0.4734 - val_loss: 0.4711 - val_acc: 0.8587 - val_f1_m: 0.8586 - val_precision_m: 0.8586 - val_recall_m: 0.8586\n",
      "Epoch 14/15\n",
      "24/24 [==============================] - 7s 293ms/step - loss: 0.2570 - acc: 0.7109 - f1_m: 0.6634 - precision_m: 0.8249 - recall_m: 0.5606 - val_loss: 0.4371 - val_acc: 0.8478 - val_f1_m: 0.8482 - val_precision_m: 0.8482 - val_recall_m: 0.8482\n",
      "Epoch 15/15\n",
      "24/24 [==============================] - 7s 292ms/step - loss: 0.2816 - acc: 0.6872 - f1_m: 0.6403 - precision_m: 0.8938 - recall_m: 0.5063 - val_loss: 0.5433 - val_acc: 0.8478 - val_f1_m: 0.8482 - val_precision_m: 0.8482 - val_recall_m: 0.8482\n",
      "Training completed in time:  0:01:52.549914\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "# model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "start=datetime.now()\n",
    "# history = model.fit(x_train, y_train, validation_split=0.3, epochs=10, verbose=0)\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=32,epochs=15)\n",
    "\n",
    "duration=datetime.now() - start\n",
    "print(\"Training completed in time: \",duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.5432752966880798\n",
      "f1 score:  0.8482142090797424\n",
      "precision:  0.848214328289032\n",
      "accuracy:  0.8478260636329651\n",
      "recall:  0.848214328289032\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
    "# test_accuracy=model.evaluate(x_test,y_test,verbose=1)\n",
    "# print(test_accuracy[1])\n",
    "# test_accuracy\n",
    "print(\"loss: \",loss)\n",
    "print(\"f1 score: \",f1_score)\n",
    "print(\"precision: \",precision)\n",
    "print(\"accuracy: \",accuracy)\n",
    "print(\"recall: \",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  5  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 0  0  1 78  0]\n",
      " [ 0  0  0  6  0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test) \n",
    "y_pred = np.argmax(y_pred, axis = 1) \n",
    "label = np.argmax(y_test,axis = 1) \n",
    "\n",
    "# print(pred.shape)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(label,y_pred))\n",
    "# print(\"y_test:\\n\", label)\n",
    "# print(\"y_pred:\\n\",y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
