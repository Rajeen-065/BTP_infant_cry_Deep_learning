{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob,pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype = \"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor(audio):\n",
    "    librosa_audio_data, librosa_sample_rate=librosa.load(audio)\n",
    "    mfccs_features= librosa.feature.mfcc(y=librosa_audio_data, sr= librosa_sample_rate,n_mfcc=20)\n",
    "    mfccs_scaled_features=np.mean(mfccs_features.T,axis=0)                             \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(test_size=0.2):\n",
    "#     x,y = [],[]\n",
    "#     for file in glob.glob(r\"D:\\BTP\\infant cry\\donateacry_corpus_cleaned_and_updated_data\\*\"):\n",
    "#         label = os.path.basename(file)\n",
    "#         for audio in glob.glob(file+\"\\*.wav\"):\n",
    "# #             print(audio)\n",
    "#             feature = featureExtractor(audio)\n",
    "#             x.append(feature)\n",
    "#             y.append(label)\n",
    "#     return train_test_split(np.array(x), np.array(y), test_size=test_size, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x_train),len(y_train),len(x_test),len(y_test))\n",
    "# print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features=[]\n",
    "def load_data():\n",
    "    c=0\n",
    "    for file in glob.glob(r\"D:\\BTP\\infant cry\\donateacry_corpus_cleaned_and_updated_data\\*\"):\n",
    "        label = os.path.basename(file)\n",
    "        for audio in glob.glob(file+\"\\*.wav\"):\n",
    "#             print(audio)\n",
    "            if(label=='hungry'):\n",
    "                if(c>200):\n",
    "                    continue\n",
    "                c+=1\n",
    "            feature = featureExtractor(audio)\n",
    "            extracted_features.append([feature,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-497.25443, 110.52981, -51.0884, -15.25888, 1...</td>\n",
       "      <td>belly_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-497.26553, 151.22801, -56.617985, -1.158033,...</td>\n",
       "      <td>belly_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-421.2681, 153.3781, -55.931305, -7.050015, 6...</td>\n",
       "      <td>belly_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-383.0191, 164.00575, -70.79439, -8.87635, 8....</td>\n",
       "      <td>belly_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-310.78342, 171.10025, -66.29349, 4.647664, 1...</td>\n",
       "      <td>belly_pain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature       class\n",
       "0  [-497.25443, 110.52981, -51.0884, -15.25888, 1...  belly_pain\n",
       "1  [-497.26553, 151.22801, -56.617985, -1.158033,...  belly_pain\n",
       "2  [-421.2681, 153.3781, -55.931305, -7.050015, 6...  belly_pain\n",
       "3  [-383.0191, 164.00575, -70.79439, -8.87635, 8....  belly_pain\n",
       "4  [-310.78342, 171.10025, -66.29349, 4.647664, 1...  belly_pain"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 2)\n"
     ]
    }
   ],
   "source": [
    "print(extracted_features_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_file_path='belly_pain.wav'\n",
    "# mfcc=featureExtractor(audio_file_path)\n",
    "# print(mfcc)\n",
    "# print(mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "Y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 20) (276,)\n",
      "['belly_pain' 'belly_pain' 'belly_pain' 'belly_pain' 'belly_pain'\n",
      " 'belly_pain' 'belly_pain' 'belly_pain' 'belly_pain' 'belly_pain'\n",
      " 'belly_pain' 'belly_pain' 'belly_pain' 'belly_pain' 'belly_pain'\n",
      " 'belly_pain' 'burping' 'burping' 'burping' 'burping' 'burping' 'burping'\n",
      " 'burping' 'burping' 'discomfort' 'discomfort' 'discomfort' 'discomfort'\n",
      " 'discomfort' 'discomfort' 'discomfort' 'discomfort' 'discomfort'\n",
      " 'discomfort' 'discomfort' 'discomfort' 'discomfort' 'discomfort'\n",
      " 'discomfort' 'discomfort' 'discomfort' 'discomfort' 'discomfort'\n",
      " 'discomfort' 'discomfort' 'discomfort' 'discomfort' 'discomfort'\n",
      " 'discomfort' 'discomfort' 'discomfort' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry'\n",
      " 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'hungry' 'tired' 'tired'\n",
      " 'tired' 'tired' 'tired' 'tired' 'tired' 'tired' 'tired' 'tired' 'tired'\n",
      " 'tired' 'tired' 'tired' 'tired' 'tired' 'tired' 'tired' 'tired' 'tired'\n",
      " 'tired' 'tired' 'tired' 'tired']\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(Y))\n",
    "# Y=np.array(pd.get_dummies(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# BUILDING MODEL\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "model=Sequential()\n",
    "#first layer\n",
    "model.add(Dense(100,input_shape=(20,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "          \n",
    "# final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               2100      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 505       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 42,905\n",
      "Trainable params: 42,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0682 - accuracy: 0.7091 - val_loss: 0.9354 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93542, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9901 - accuracy: 0.7136 - val_loss: 0.9327 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.93542 to 0.93268, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0165 - accuracy: 0.7045 - val_loss: 0.9330 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.93268\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0735 - accuracy: 0.7000 - val_loss: 0.9225 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.93268 to 0.92251, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9958 - accuracy: 0.7091 - val_loss: 0.9306 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.92251\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0067 - accuracy: 0.7136 - val_loss: 0.9430 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.92251\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9951 - accuracy: 0.7091 - val_loss: 0.9609 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.92251\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0468 - accuracy: 0.7091 - val_loss: 0.9653 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.92251\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0842 - accuracy: 0.7091 - val_loss: 0.9516 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.92251\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0830 - accuracy: 0.7045 - val_loss: 0.9313 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.92251\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9918 - accuracy: 0.7091 - val_loss: 0.9292 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.92251\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9231 - accuracy: 0.7136 - val_loss: 0.9271 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.92251\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0114 - accuracy: 0.7045 - val_loss: 0.9215 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.92251 to 0.92150, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0807 - accuracy: 0.7136 - val_loss: 0.9258 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.92150\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0059 - accuracy: 0.7091 - val_loss: 0.9278 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.92150\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0491 - accuracy: 0.7136 - val_loss: 0.9385 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.92150\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0478 - accuracy: 0.7045 - val_loss: 0.9372 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.92150\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9926 - accuracy: 0.7136 - val_loss: 0.9268 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.92150\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9838 - accuracy: 0.7091 - val_loss: 0.9271 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.92150\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0251 - accuracy: 0.7136 - val_loss: 0.9317 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.92150\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0031 - accuracy: 0.7091 - val_loss: 0.9374 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.92150\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9598 - accuracy: 0.7091 - val_loss: 0.9385 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.92150\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0396 - accuracy: 0.7136 - val_loss: 0.9368 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.92150\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9950 - accuracy: 0.7136 - val_loss: 0.9310 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.92150\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0039 - accuracy: 0.7136 - val_loss: 0.9284 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.92150\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0748 - accuracy: 0.7045 - val_loss: 0.9264 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.92150\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0365 - accuracy: 0.7045 - val_loss: 0.9281 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.92150\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9832 - accuracy: 0.7091 - val_loss: 0.9233 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.92150\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0172 - accuracy: 0.7091 - val_loss: 0.9196 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.92150 to 0.91955, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0167 - accuracy: 0.7136 - val_loss: 0.9234 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.91955\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9775 - accuracy: 0.7091 - val_loss: 0.9260 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.91955\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0144 - accuracy: 0.7136 - val_loss: 0.9280 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.91955\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9717 - accuracy: 0.7091 - val_loss: 0.9381 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.91955\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9679 - accuracy: 0.7091 - val_loss: 0.9361 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.91955\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9667 - accuracy: 0.7136 - val_loss: 0.9294 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.91955\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9921 - accuracy: 0.7136 - val_loss: 0.9223 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.91955\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9904 - accuracy: 0.7091 - val_loss: 0.9160 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.91955 to 0.91603, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.0079 - accuracy: 0.7136 - val_loss: 0.9173 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.91603\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0188 - accuracy: 0.7136 - val_loss: 0.9160 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.91603\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9836 - accuracy: 0.7136 - val_loss: 0.9226 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.91603\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9783 - accuracy: 0.7091 - val_loss: 0.9237 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.91603\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9800 - accuracy: 0.7136 - val_loss: 0.9101 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.91603 to 0.91011, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9893 - accuracy: 0.7136 - val_loss: 0.9072 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.91011 to 0.90722, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0017 - accuracy: 0.7091 - val_loss: 0.9079 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.90722\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0296 - accuracy: 0.7136 - val_loss: 0.9123 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.90722\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9872 - accuracy: 0.7091 - val_loss: 0.9127 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.90722\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9748 - accuracy: 0.7091 - val_loss: 0.9053 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.90722 to 0.90531, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0048 - accuracy: 0.7091 - val_loss: 0.9037 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.90531 to 0.90373, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0173 - accuracy: 0.7091 - val_loss: 0.9042 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.90373\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9535 - accuracy: 0.7136 - val_loss: 0.9064 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.90373\n",
      "Training completed in time:  0:00:05.833848\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs=50\n",
    "num_batch_size=32\n",
    "\n",
    "checkpointer=ModelCheckpoint(filepath='saved_models/audio_classification.hdf5',\n",
    "                             verbose=1,save_best_only=True)\n",
    "start=datetime.now()\n",
    "model.fit(X_train,y_train,batch_size=num_batch_size,epochs=num_epochs,\n",
    "          validation_data=(X_test,y_test),callbacks=[checkpointer] )\n",
    "duration=datetime.now() - start\n",
    "print(\"Training completed in time: \",duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.9063510894775391\n",
      "0.7857142686843872\n"
     ]
    }
   ],
   "source": [
    "loss,test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(\"loss: \",loss)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename='burping.wav'\n",
    "prediction_feature=featureExtractor(filename).reshape(1,-1)\n",
    "# model.predict_classes(prediction_feature)\n",
    "predicted_label=model.predict_classes(prediction_feature)\n",
    "print(predicted_label)\n",
    "predcited_class=labelencoder.inverse_transform(predicted_label)\n",
    "predcited_class\n",
    "# (model.predict(prediction_feature) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
